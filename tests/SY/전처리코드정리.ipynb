{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경제지표 데이터 전처리\n",
    "\n",
    "filled_economic_indicators.csv 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yfinance에서 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작일과 종료일 설정\n",
    "start_date = '2015-01-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# 데이터를 저장할 빈 데이터프레임 생성\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "# 각 지표의 티커 심볼 정의\n",
    "tickers = {\n",
    "    'KOSPI': '^KS11',  # KOSPI\n",
    "    'USD/KRW': 'KRW=X',  # 원달러 환율\n",
    "    'WTI': 'CL=F',  # WTI 원유 선물\n",
    "    'VIX': '^VIX',  # VIX 지수\n",
    "    'Gold': 'GC=F',  # 금 선물\n",
    "    'Silver': 'SI=F',  # 은 선물\n",
    "    'MOVE' : '^MOVE' # MOVE Index\n",
    "}\n",
    "\n",
    "# 각 티커에 대해 데이터 다운로드\n",
    "for name, ticker in tickers.items():\n",
    "    try:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date)\n",
    "        # 종가만 사용\n",
    "        df_final[name] = df['Close']\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {name}: {e}\")\n",
    "\n",
    "# MOVE 인덱스는 별도로 처리해야 할 수 있음 (Bloomberg 등의 유료 데이터 소스 필요)\n",
    "print(\"Note: MOVE Index data needs to be obtained from a separate source like Bloomberg\")\n",
    "\n",
    "# 결측치 처리\n",
    "df_final = df_final.fillna(method='ffill')\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"\\nFirst few rows of the data:\")\n",
    "print(df_final.head())\n",
    "\n",
    "# 기본 통계 확인\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df_final.describe())\n",
    "\n",
    "# CSV 파일로 저장\n",
    "output_filename = '_economic_indicators_.csv'\n",
    "df_final.to_csv(output_filename)\n",
    "print(f\"\\nData saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경제지표 데이터 결측치 채우기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv('_economic_indicators_.csv', encoding='utf-8')\n",
    "\n",
    "# Date 컬럼을 datetime으로 변환\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# 시작일과 마지막일 추출\n",
    "start_date = df['Date'].min()\n",
    "end_date = df['Date'].max()\n",
    "\n",
    "# 모든 날짜가 포함된 데이터프레임 생성\n",
    "all_dates = pd.DataFrame(\n",
    "    {'Date': pd.date_range(start_date, end_date, freq='D')}\n",
    ")\n",
    "\n",
    "# 기존 데이터와 병합\n",
    "filled_df = pd.merge(all_dates, df, on='Date', how='left')\n",
    "\n",
    "# 결측치를 이전 값으로 채우기\n",
    "filled_df = filled_df.ffill()\n",
    "\n",
    "# 결과 저장\n",
    "filled_df.to_csv('filled_economic_indicators.csv', index=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"처리된 데이터 샘플:\")\n",
    "print(filled_df.head())\n",
    "print(\"\\n결측치 확인:\")\n",
    "print(filled_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트렌드 데이터 어종별로 그룹화\n",
    "\n",
    "merged_trends.csv 생성  \n",
    "nst_@@@ --> 그룹화_nst_@@@\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_age_groups(file_path):\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    \n",
    "    # 연령대 그룹 매핑 딕셔너리 생성\n",
    "    age_mapping = {\n",
    "        '19_24': '20대',\n",
    "        '25_29': '20대',\n",
    "        '30_34': '30대',\n",
    "        '35_39': '30대',\n",
    "        '40_44': '40대',\n",
    "        '45_49': '40대',\n",
    "        '50_54': '50대',\n",
    "        '55_59': '50대',\n",
    "        '60_80': '60대 이상'\n",
    "    }\n",
    "    \n",
    "    # 원하는 연령대만 필터링\n",
    "    df = df[df['age'].isin(age_mapping.keys())]\n",
    "    \n",
    "    # 새로운 연령대 컬럼 생성\n",
    "    df['age_group'] = df['age'].map(age_mapping)\n",
    "    \n",
    "    # 일자별, 새로운 연령대별로 score 합산\n",
    "    result = df.groupby(['date', 'name', 'age_group'])['score'].sum().reset_index()\n",
    "    \n",
    "    # 피벗 테이블로 변환하여 보기 좋게 정리\n",
    "    pivot_result = result.pivot(index=['date', 'name'], \n",
    "                              columns='age_group', \n",
    "                              values='score').reset_index()\n",
    "    \n",
    "    # 컬럼 순서 정리\n",
    "    column_order = [ 'date', 'name', '20대', '30대', '40대', '50대', '60대 이상']\n",
    "    pivot_result = pivot_result[column_order]\n",
    "    \n",
    "    return pivot_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 수산물 종류별 파일 경로 및 이름 설정\n",
    "fish_files = {\n",
    "    '광어': '../../data/raw/nst_광어_trend_2025-01-17.csv',\n",
    "    '농어': '../../data/raw/nst_농어_trend_2025-01-17.csv',\n",
    "    '대게': '../../data/raw/nst_대게_trend_2025-01-17.csv',\n",
    "    '방어': '../../data/raw/nst_방어_trend_2025-01-17.csv',\n",
    "    '연어': '../../data/raw/nst_연어_trend_2025-01-17.csv',\n",
    "    '우럭': '../../data/raw/nst_우럭_trend_2025-01-17.csv',\n",
    "    '참돔': '../../data/raw/nst_참돔_trend_2025-01-17.csv'\n",
    "}\n",
    "\n",
    "# 📌 개별 파일 저장 + 결과 리스트로 출력 준비\n",
    "all_results = {}\n",
    "\n",
    "# 📌 모든 파일 처리\n",
    "for fish, file_path in fish_files.items():\n",
    "    try:\n",
    "        processed_df = process_age_groups(file_path, fish)\n",
    "\n",
    "        # 개별 파일 저장\n",
    "        output_filename = f'그룹화_nst_{fish}_trend_2025-01-17.csv'\n",
    "        processed_df.to_csv(output_filename, index=False)\n",
    "\n",
    "        # 결과 리스트에 추가 (첫 3개 행만 저장)\n",
    "        all_results[fish] = processed_df.head(3)\n",
    "\n",
    "        print(f\"✅ '{output_filename}' 저장 완료!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {fish}: {e}\")\n",
    "\n",
    "# 📌 최종 처리된 결과 출력 (각각 3개 행만 출력)\n",
    "print(\"\\n📊 최종 처리된 결과 미리보기 (각각 상위 3개 행)\\n\")\n",
    "for fish, df_sample in all_results.items():\n",
    "    print(f\"📌 {fish} 데이터 샘플:\")\n",
    "    print(df_sample)\n",
    "    print(\"-\" * 50)  # 구분선 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기상 데이터 전처리\n",
    "\n",
    "weatherdata_processed.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 정의\n",
    "\n",
    "def create_weather_columns(df, station_cols, output_path):\n",
    "   result_df = df.copy()\n",
    "   result_df['일시'] = pd.to_datetime(result_df['일시'])\n",
    "   \n",
    "   final_df = pd.DataFrame({'일시': result_df['일시'].unique()})\n",
    "   \n",
    "   for station, columns in station_cols.items():\n",
    "       station_data = result_df[result_df['지점'] == station].copy()\n",
    "       \n",
    "       for orig_col, new_col in columns:\n",
    "           station_col = station_data[['일시', orig_col]].copy()\n",
    "           final_df = pd.merge(final_df, station_col.rename(columns={orig_col: new_col}), \n",
    "                             on='일시', how='left')\n",
    "   \n",
    "   # 칼럼을 가나다순으로 정렬 ('일시' 컬럼은 첫번째로 유지)\n",
    "   sorted_cols = ['일시'] + sorted([col for col in final_df.columns if col != '일시'])\n",
    "   result = final_df[sorted_cols].sort_values('일시')\n",
    "   \n",
    "   result.to_csv(output_path, index=False, encoding='utf-8')\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('forecast_agg.csv', encoding='utf-8')\n",
    "\n",
    "# 피쳐 선택\n",
    "station_columns = {\n",
    "\t22105: [\n",
    "\t\t('기온', '광어_기온_22105'),\n",
    "\t\t('기온', '농어_기온_22105'),\n",
    "\t\t('기온', '대게_기온_22105'),\n",
    "\t\t('파주기', '대게_파주기_22105'),\n",
    "\t\t('파주기', '방어_파주기_22105'),\n",
    "\t\t('기온', '연어_기온_22105'),\n",
    "\t\t('습도', '연어_습도_22105')\n",
    "\t],\n",
    "    \n",
    "\t22107: [\n",
    "\t\t('수온', '광어_수온_22107'),\n",
    "\t\t('수온', '농어_수온_22107'),\n",
    "\t\t('수온', '방어_수온_22107'),\n",
    "\t\t('수온', '연어_수온_22107'),\n",
    "\t\t('수온', '참돔_수온_22107')\n",
    "\t],\n",
    "\n",
    "\t22186: [\n",
    "\t\t('습도', '광어_습도_22186'),\n",
    "\t\t('습도', '농어_습도_22186'),\n",
    "\t\t('기온', '우럭_기온_22186'),\n",
    "\t\t('수온', '우럭_수온_22186')\n",
    "\t\t],\n",
    "        \n",
    "\t22188: [\n",
    "\t\t('수온', '대게_수온_22188'),\n",
    "\t\t('습도', '대게_습도_22188')\n",
    "\t\t],        \n",
    "\n",
    "\t22189: [\n",
    "\t\t('파주기', '우럭_파주기_22189')\n",
    "\t\t],       \n",
    "\n",
    "\t22190: [\n",
    "\t\t('파주기', '광어_파주기_22190'),\n",
    "        ('파주기', '농어_파주기_22190'),\n",
    "        ('기온', '방어_기온_22190'),\n",
    "        ('습도', '방어_습도_22190'),\n",
    "        ('파주기', '연어_파주기_22190'),\n",
    "        ('습도', '우럭_습도_22190'),\n",
    "        ('기온', '참돔_기온_22190'),\n",
    "        ('습도', '참돔_습도_22190'),\n",
    "        ('파주기', '참돔_파주기_22190')\n",
    "\t\t]  \n",
    "\n",
    "\t}\n",
    "\n",
    "result = create_weather_columns(df, station_columns, 'weatherdata_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 하나로 합치기\n",
    "\n",
    "merged_all_data.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fish_trends(file_paths, output_path):\n",
    "   # 첫 번째 파일 로드 및 name 컬럼 제거\n",
    "   merged_df = pd.read_csv(file_paths[0], encoding='utf-8')\n",
    "   merged_df = merged_df.drop('name', axis=1)\n",
    "   merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "   \n",
    "   # 나머지 파일들 병합\n",
    "   for file_path in file_paths[1:]:\n",
    "       df = pd.read_csv(file_path, encoding='utf-8')\n",
    "       df = df.drop('name', axis=1)\n",
    "       df['date'] = pd.to_datetime(df['date'])\n",
    "       merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
    "   \n",
    "   # 날짜순 정렬\n",
    "   result = merged_df.sort_values('date')\n",
    "   \n",
    "   # CSV 저장\n",
    "   result.to_csv(output_path, index=False, encoding='utf-8')\n",
    "   return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시:\n",
    "files = [\n",
    "    '그룹화_nst_광어_trend_2025-01-17.csv', \n",
    "    '그룹화_nst_농어_trend_2025-01-17.csv', \n",
    "    '그룹화_nst_대게_trend_2025-01-17.csv', \n",
    "    '그룹화_nst_방어_trend_2025-01-17.csv', \n",
    "    '그룹화_nst_연어_trend_2025-01-17.csv', \n",
    "    '그룹화_nst_우럭_trend_2025-01-17.csv', \n",
    "    '그룹화_nst_참돔_trend_2025-01-17.csv'\n",
    "    ]\n",
    "\n",
    "result = merge_fish_trends(files, 'merged_trends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(file_paths, output_path):\n",
    "   # 첫 번째 파일 로드 및 name 컬럼 제거\n",
    "   merged_df = pd.read_csv(file_paths[0], encoding='utf-8')\n",
    "   merged_df = merged_df.drop('name', axis=1)\n",
    "   merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "   \n",
    "   # 나머지 파일들 병합\n",
    "   for file_path in file_paths[1:]:\n",
    "       df = pd.read_csv(file_path, encoding='utf-8')\n",
    "       df = df.drop('name', axis=1)\n",
    "       df['date'] = pd.to_datetime(df['date'])\n",
    "       merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
    "   \n",
    "   # 날짜순 정렬\n",
    "   result = merged_df.sort_values('date')\n",
    "   \n",
    "   # CSV 저장\n",
    "   result.to_csv(output_path, index=False, encoding='utf-8')\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없는 칼럼 제거\n",
    "\n",
    "df_광어 = pd.read_csv('item_price_lag_filled.csv')\n",
    "df_광어 = df_광어.drop('minPrice', axis=1)\n",
    "df_광어.to_csv('item_price_lag_filled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_data(output_path='merged_all_data.csv'):\n",
    "   # 각 파일 로드 및 전처리\n",
    "   \n",
    "   economic = pd.read_csv('_filled_economic_indicators.csv', encoding='utf-8')\n",
    "   economic['Date'] = pd.to_datetime(economic['Date'])\n",
    "   economic = economic.rename(columns={'Date': '날짜'})\n",
    "   \n",
    "   trends = pd.read_csv('merged_trends.csv', encoding='utf-8')\n",
    "   trends['date'] = pd.to_datetime(trends['date'])\n",
    "   trends = trends.rename(columns={'date': '날짜'})\n",
    "   \n",
    "   weather = pd.read_csv('_weatherdata_processed.csv', encoding='utf-8')\n",
    "   weather['date'] = pd.to_datetime(weather['date'])\n",
    "   weather = weather.rename(columns={'date': '날짜'})\n",
    "   \n",
    "   # 모든 날짜 추출\n",
    "   all_dates = pd.concat([\n",
    "        economic['날짜'], \n",
    "        trends['날짜'], \n",
    "       weather['날짜']\n",
    "   ]).unique()\n",
    "   \n",
    "   # 날짜 기준 데이터프레임 생성\n",
    "   date_df = pd.DataFrame({'날짜': all_dates})\n",
    "   date_df = date_df.sort_values('날짜')\n",
    "   \n",
    "   # 데이터 병합\n",
    "   dfs = [\n",
    "\t\tdate_df, \n",
    "\t\teconomic, \n",
    "\t\ttrends,\n",
    "\t\tweather\n",
    "   ]\n",
    "   \n",
    "   result = dfs[0]\n",
    "   for df in dfs[1:]:\n",
    "       result = pd.merge(result, df, on='날짜', how='left')\n",
    "   \n",
    "   # 결과 저장\n",
    "   result.to_csv(output_path, index=False, encoding='utf-8')\n",
    "   return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = merge_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치 채우기\n",
    "\n",
    " \"filled_merged_all_data.csv\" 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fill_missing_values(file_path, output_path):\n",
    "    \"\"\"\n",
    "    CSV 파일에서 결측치를 `ffill`을 사용하여 채우되, 이전 값이 없으면 그대로 둠.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): 입력 CSV 파일 경로.\n",
    "        output_path (str): 처리된 데이터를 저장할 경로.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: 결측치가 채워진 데이터프레임.\n",
    "    \"\"\"\n",
    "    \n",
    "    # CSV 파일 로드\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 결측치 확인 (처리 전)\n",
    "    missing_before = df.isnull().sum()\n",
    "\n",
    "    # 결측치 `ffill`로 채우기 (이전 값이 없으면 그대로 둠)\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # 결측치 확인 (처리 후)\n",
    "    missing_after = df.isnull().sum()\n",
    "\n",
    "    # 변경된 결측치 개수 출력\n",
    "    missing_summary = pd.DataFrame({'Before': missing_before, 'After': missing_after})\n",
    "    print(\"\\n🔍 결측치 처리 전후 비교:\")\n",
    "    print(missing_summary)\n",
    "\n",
    "    # 처리된 데이터 저장\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n✅ 처리된 데이터가 '{output_path}'에 저장되었습니다.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 결측치 처리 전후 비교:\n",
      "                Before  After\n",
      "날짜                   0      0\n",
      "활연어_거래량(톤)        1107   1097\n",
      "활연어_가격(NOK/kg)    1107   1097\n",
      "광어_대              1938   1098\n",
      "광어_중              1938   1098\n",
      "...                ...    ...\n",
      "우럭_파주기_22189       487    355\n",
      "참돔_기온_22190        452    342\n",
      "참돔_수온_22107        203      0\n",
      "참돔_습도_22190        454    342\n",
      "참돔_파주기_22190       414    342\n",
      "\n",
      "[122 rows x 2 columns]\n",
      "\n",
      "✅ 처리된 데이터가 'filled_merged_all_data.csv'에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_38656\\1915651589.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ 실행 예시\n",
    "input_file = \"../../data/features/merged_all_data.csv\"  # 원본 데이터 경로\n",
    "output_file = \"filled_merged_all_data.csv\"  # 저장될 파일 경로\n",
    "\n",
    "# 함수 실행\n",
    "filled_df = fill_missing_values(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어종별 가격 데이터 파일 분리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('pp/item_price_lag_filled.csv')\n",
    "\n",
    "# 유니크한 item 목록 확인\n",
    "unique_items = df['item'].unique()\n",
    "\n",
    "# 각 item별로 데이터 분리하여 저장\n",
    "for item in unique_items:\n",
    "    # 해당 item의 데이터만 필터링\n",
    "    item_df = df[df['item'] == item]\n",
    "    \n",
    "    # 파일명에 사용할 수 있게 item 이름 처리 (특수문자 등 제거)\n",
    "    file_name = f\"{item.replace(' ', '_').replace('/', '_')}_price_data.csv\"\n",
    "    \n",
    "    # CSV 파일로 저장\n",
    "    item_df.to_csv(file_name, index=False, encoding='utf-8')\n",
    "    \n",
    "    # 저장 완료 메시지 출력\n",
    "    print(f\"{item} 데이터가 {file_name}으로 저장되었습니다.\")\n",
    "    print(f\"행 수: {len(item_df)}\")\n",
    "\n",
    "# 전체 처리 완료 메시지\n",
    "print(\"\\n전체 품목 분리 저장이 완료되었습니다.\")\n",
    "print(f\"총 {len(unique_items)}개의 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수랑 인어교주해적단 가격이랑 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합친 데이터에 타임래그 적용하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env311_cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

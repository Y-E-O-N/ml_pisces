{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import glob\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 138942 entries, 1041 to 163865\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   priceDate       138942 non-null  datetime64[ns]\n",
      " 1   item            138942 non-null  object        \n",
      " 2   market          138942 non-null  object        \n",
      " 3   minPrice        138942 non-null  float64       \n",
      " 4   avgPrice        138942 non-null  float64       \n",
      " 5   maxPrice        138942 non-null  float64       \n",
      " 6   avgPrice_lag_1  138901 non-null  float64       \n",
      " 7   avgPrice_lag_2  138860 non-null  float64       \n",
      " 8   avgPrice_lag_3  138819 non-null  float64       \n",
      " 9   avgPrice_lag_7  138659 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(7), object(2)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/processed/item_price_lag_filled.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data['priceDate'] = pd.to_datetime(data['priceDate'], errors='coerce')\n",
    "# 2018년 이후 데이터터\n",
    "data = data[data['priceDate'] >= '2018-01-01']\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '우럭'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "if not file_list:\n",
    "    raise FileNotFoundError(\"기상 데이터 파일이 존재하지 않습니다. 경로를 확인하세요.\")\n",
    "\n",
    "# 각 파일을 개별적으로 처리 후 리스트에 저장\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby(['지점', '날짜']).mean().reset_index()\n",
    "\n",
    "# 지역별 데이터 분리\n",
    "selected_locations = {'부안': 22186, '가거도': [22297, 22193], '통영': 22188}\n",
    "df_buan = daily_avg[daily_avg['지점'] == selected_locations['부안']]\n",
    "df_gageodo = daily_avg[daily_avg['지점'].isin(selected_locations['가거도'])].groupby('날짜').mean().reset_index()\n",
    "df_tongyoung = daily_avg[daily_avg['지점'] == selected_locations['통영']]\n",
    "\n",
    "def analyze_correlation(weather_df, price_df, max_lag=30):\n",
    "    best_lag = 0\n",
    "    best_corr = -1\n",
    "    for lag in range(max_lag + 1):\n",
    "        shifted_prices = price_df.copy()\n",
    "        shifted_prices['날짜'] = shifted_prices['날짜'] - pd.Timedelta(days=lag)\n",
    "        merged = pd.merge(shifted_prices, weather_df, on='날짜', how='inner')\n",
    "        if not merged.empty:\n",
    "            scaler = StandardScaler()\n",
    "            \n",
    "            # 수치형 데이터만 선택\n",
    "            numeric_cols = merged.select_dtypes(include=['float64', 'int64']).columns\n",
    "            weather_scaled = scaler.fit_transform(merged[numeric_cols])\n",
    "            price_scaled = scaler.fit_transform(merged[['avgPrice']])\n",
    "\n",
    "            corr, _ = pearsonr(price_scaled.flatten(), weather_scaled[:, 0])\n",
    "            if corr > best_corr:\n",
    "                best_corr = corr\n",
    "                best_lag = lag\n",
    "    return best_lag, best_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이하 우럭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 지역과 참돔 가격의 상관계수:\n",
      "지점: -0.3785\n",
      "풍속(m/s): 0.2295\n",
      "풍향(deg): 0.2297\n",
      "GUST풍속(m/s): 0.2741\n",
      "현지기압(hPa): 0.3426\n",
      "습도(%): -0.4572\n",
      "기온(°C): -0.3452\n",
      "수온(°C): -0.2187\n",
      "최대파고(m): 0.2275\n",
      "유의파고(m): 0.2294\n",
      "평균파고(m): 0.2306\n",
      "파주기(sec): 0.2638\n",
      "파향(deg): 0.1734\n"
     ]
    }
   ],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '우럭'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby('날짜').mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 기상 데이터와 가격 데이터 병합\n",
    "merged_data = pd.merge(rockfish_prices, daily_avg, on='날짜', how='inner')\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_overall_correlation(data):\n",
    "    numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col != 'avgPrice':\n",
    "            scaler = StandardScaler()\n",
    "            weather_scaled = scaler.fit_transform(data[[col]])\n",
    "            price_scaled = scaler.fit_transform(data[['avgPrice']])\n",
    "            corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "            correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 전체 데이터 상관계수 계산\n",
    "overall_correlations = calculate_overall_correlation(merged_data)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"전체 지역과 우럭 가격의 상관계수:\")\n",
    "for key, value in overall_correlations.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가거도, 부안, 통영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgPrice': np.float64(1.0),\n",
       " '지점': np.float64(-0.2909706006666098),\n",
       " '풍속(m/s)': np.float64(0.2746287583498614),\n",
       " '풍향(deg)': np.float64(0.2029877026244553),\n",
       " 'GUST풍속(m/s)': np.float64(0.2872707617250629),\n",
       " '현지기압(hPa)': np.float64(0.4037666148048912),\n",
       " '습도(%)': np.float64(-0.4341703792340106),\n",
       " '기온(°C)': np.float64(-0.3619870290917399),\n",
       " '수온(°C)': np.float64(-0.25429761048978494),\n",
       " '최대파고(m)': np.float64(0.13499602336488062),\n",
       " '유의파고(m)': np.float64(0.14364934288625494),\n",
       " '평균파고(m)': np.float64(0.1432662483130067),\n",
       " '파주기(sec)': np.float64(0.1851249401592211),\n",
       " '파향(deg)': np.float64(0.23659185046220035)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '우럭'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "# 각 파일을 개별적으로 처리 후 리스트에 저장\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby(['지점', '날짜']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 지역별 데이터 분리 (부안, 가거도, 통영)\n",
    "selected_locations = {'부안': 22186, '가거도': [22297, 22193], '통영': 22188}\n",
    "df_buan = daily_avg[daily_avg['지점'] == selected_locations['부안']]\n",
    "df_gageodo = daily_avg[daily_avg['지점'].isin(selected_locations['가거도'])].groupby('날짜').mean().reset_index()\n",
    "df_tongyoung = daily_avg[daily_avg['지점'] == selected_locations['통영']]\n",
    "\n",
    "# 모든 지역 데이터 통합\n",
    "all_weather_data = pd.concat([df_buan, df_gageodo, df_tongyoung]).groupby('날짜').mean().reset_index()\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_correlations(weather_df, price_df):\n",
    "    merged = pd.merge(price_df, weather_df, on='날짜', how='inner')\n",
    "    numeric_cols = merged.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        scaler = StandardScaler()\n",
    "        weather_scaled = scaler.fit_transform(merged[[col]])\n",
    "        price_scaled = scaler.fit_transform(merged[['avgPrice']])\n",
    "        corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "        correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 개별 항목과의 상관계수 계산\n",
    "individual_correlations = calculate_correlations(all_weather_data, rockfish_prices)\n",
    "individual_correlations\n",
    "\n",
    "# # # 유의미한 항목 선별 (절대 상관계수 0.3 이상)\n",
    "# significant_columns = [k for k, v in individual_correlations.items() if abs(v) >= 0.3]\n",
    "\n",
    "# # 선택된 유의미한 항목만 추출\n",
    "# if significant_columns:\n",
    "#     significant_data = all_weather_data[['날짜'] + significant_columns]\n",
    "#     combined_correlation = calculate_correlations(significant_data, rockfish_prices)\n",
    "# else:\n",
    "#     combined_correlation = {}\n",
    "\n",
    "# # 결과 출력\n",
    "# individual_correlations, combined_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이하 참돔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 지역과 참돔 가격의 상관계수:\n",
      "지점: 0.7174\n",
      "풍속(m/s): 0.0461\n",
      "풍향(deg): 0.0222\n",
      "GUST풍속(m/s): 0.0614\n",
      "현지기압(hPa): 0.0759\n",
      "습도(%): 0.0151\n",
      "기온(°C): 0.0045\n",
      "수온(°C): 0.0912\n",
      "최대파고(m): 0.0114\n",
      "유의파고(m): 0.0366\n",
      "평균파고(m): 0.0118\n",
      "파주기(sec): -0.2234\n",
      "파향(deg): -0.0484\n"
     ]
    }
   ],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '참돔'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby('날짜').mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 기상 데이터와 가격 데이터 병합\n",
    "merged_data = pd.merge(rockfish_prices, daily_avg, on='날짜', how='inner')\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_overall_correlation(data):\n",
    "    numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col != 'avgPrice':\n",
    "            scaler = StandardScaler()\n",
    "            weather_scaled = scaler.fit_transform(data[[col]])\n",
    "            price_scaled = scaler.fit_transform(data[['avgPrice']])\n",
    "            corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "            correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 전체 데이터 상관계수 계산\n",
    "overall_correlations = calculate_overall_correlation(merged_data)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"전체 지역과 참돔 가격의 상관계수:\")\n",
    "for key, value in overall_correlations.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgPrice': np.float64(1.0),\n",
       " '지점': np.float64(0.38527354533824365),\n",
       " '풍속(m/s)': np.float64(0.0589457544239286),\n",
       " '풍향(deg)': np.float64(-0.008655320766031736),\n",
       " 'GUST풍속(m/s)': np.float64(0.09594358254995757),\n",
       " '현지기압(hPa)': np.float64(0.05675589788194707),\n",
       " '습도(%)': np.float64(0.012397045829841281),\n",
       " '기온(°C)': np.float64(0.04573803756912134),\n",
       " '수온(°C)': np.float64(0.11376503420992212),\n",
       " '최대파고(m)': np.float64(0.05878279355867318),\n",
       " '유의파고(m)': np.float64(0.08469307854039856),\n",
       " '평균파고(m)': np.float64(0.07211038025466467),\n",
       " '파주기(sec)': np.float64(-0.27869234991069236),\n",
       " '파향(deg)': np.float64(0.027916905034034233)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '참돔'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "# 각 파일을 개별적으로 처리 후 리스트에 저장\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby(['지점', '날짜']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 지역별 데이터 분리 (부안, 가거도, 통영)\n",
    "selected_locations = {'가거도': [22297, 22193], '통영': 22188}\n",
    "df_gageodo = daily_avg[daily_avg['지점'].isin(selected_locations['가거도'])].groupby('날짜').mean().reset_index()\n",
    "df_tongyoung = daily_avg[daily_avg['지점'] == selected_locations['통영']]\n",
    "\n",
    "# 모든 지역 데이터 통합\n",
    "all_weather_data = pd.concat([df_buan, df_gageodo, df_tongyoung]).groupby('날짜').mean().reset_index()\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_correlations(weather_df, price_df):\n",
    "    merged = pd.merge(price_df, weather_df, on='날짜', how='inner')\n",
    "    numeric_cols = merged.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        scaler = StandardScaler()\n",
    "        weather_scaled = scaler.fit_transform(merged[[col]])\n",
    "        price_scaled = scaler.fit_transform(merged[['avgPrice']])\n",
    "        corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "        correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 개별 항목과의 상관계수 계산\n",
    "individual_correlations = calculate_correlations(all_weather_data, rockfish_prices)\n",
    "individual_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이하 방어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 지역과 방어 가격의 상관계수:\n",
      "지점: 0.6250\n",
      "풍속(m/s): 0.0516\n",
      "풍향(deg): 0.0705\n",
      "GUST풍속(m/s): 0.0643\n",
      "현지기압(hPa): 0.0428\n",
      "습도(%): 0.0240\n",
      "기온(°C): -0.0695\n",
      "수온(°C): -0.0147\n",
      "최대파고(m): 0.0418\n",
      "유의파고(m): 0.0609\n",
      "평균파고(m): 0.0395\n",
      "파주기(sec): -0.2475\n",
      "파향(deg): -0.0053\n"
     ]
    }
   ],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '방어'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby('날짜').mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 기상 데이터와 가격 데이터 병합\n",
    "merged_data = pd.merge(rockfish_prices, daily_avg, on='날짜', how='inner')\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_overall_correlation(data):\n",
    "    numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col != 'avgPrice':\n",
    "            scaler = StandardScaler()\n",
    "            weather_scaled = scaler.fit_transform(data[[col]])\n",
    "            price_scaled = scaler.fit_transform(data[['avgPrice']])\n",
    "            corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "            correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 전체 데이터 상관계수 계산\n",
    "overall_correlations = calculate_overall_correlation(merged_data)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"전체 지역과 방어 가격의 상관계수:\")\n",
    "for key, value in overall_correlations.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgPrice': np.float64(0.9999999999999998),\n",
       " '지점': np.float64(0.1196726431971852),\n",
       " '풍속(m/s)': np.float64(0.054406924371199566),\n",
       " '풍향(deg)': np.float64(0.07521079533801875),\n",
       " 'GUST풍속(m/s)': np.float64(0.08824183040868319),\n",
       " '현지기압(hPa)': np.float64(0.031169153502364537),\n",
       " '습도(%)': np.float64(0.02541044103838705),\n",
       " '기온(°C)': np.float64(-0.010418222121085813),\n",
       " '수온(°C)': np.float64(0.030373423953473443),\n",
       " '최대파고(m)': np.float64(0.03640739668664986),\n",
       " '유의파고(m)': np.float64(0.05425884643807624),\n",
       " '평균파고(m)': np.float64(0.043455911982901024),\n",
       " '파주기(sec)': np.float64(-0.23389196543514995),\n",
       " '파향(deg)': np.float64(0.07463536491862163)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '방어'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "# 각 파일을 개별적으로 처리 후 리스트에 저장\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby(['지점', '날짜']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 지역별 데이터 분리 (부안, 가거도, 통영)\n",
    "selected_locations = {'가거도': [22297, 22193], '통영': 22188}\n",
    "df_gageodo = daily_avg[daily_avg['지점'].isin(selected_locations['가거도'])].groupby('날짜').mean().reset_index()\n",
    "df_tongyoung = daily_avg[daily_avg['지점'] == selected_locations['통영']]\n",
    "\n",
    "# 모든 지역 데이터 통합\n",
    "all_weather_data = pd.concat([df_buan, df_gageodo, df_tongyoung]).groupby('날짜').mean().reset_index()\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_correlations(weather_df, price_df):\n",
    "    merged = pd.merge(price_df, weather_df, on='날짜', how='inner')\n",
    "    numeric_cols = merged.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        scaler = StandardScaler()\n",
    "        weather_scaled = scaler.fit_transform(merged[[col]])\n",
    "        price_scaled = scaler.fit_transform(merged[['avgPrice']])\n",
    "        corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "        correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 개별 항목과의 상관계수 계산\n",
    "individual_correlations = calculate_correlations(all_weather_data, rockfish_prices)\n",
    "individual_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 지역과 대게게 가격의 상관계수:\n",
      "지점: 0.3759\n",
      "풍속(m/s): 0.2975\n",
      "풍향(deg): 0.2053\n",
      "GUST풍속(m/s): 0.3443\n",
      "현지기압(hPa): 0.5041\n",
      "습도(%): -0.4940\n",
      "기온(°C): -0.4931\n",
      "수온(°C): -0.3466\n",
      "최대파고(m): 0.2829\n",
      "유의파고(m): 0.2914\n",
      "평균파고(m): 0.2795\n",
      "파주기(sec): 0.1540\n",
      "파향(deg): 0.0635\n"
     ]
    }
   ],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '대게'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby('날짜').mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 기상 데이터와 가격 데이터 병합\n",
    "merged_data = pd.merge(rockfish_prices, daily_avg, on='날짜', how='inner')\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_overall_correlation(data):\n",
    "    numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col != 'avgPrice':\n",
    "            scaler = StandardScaler()\n",
    "            weather_scaled = scaler.fit_transform(data[[col]])\n",
    "            price_scaled = scaler.fit_transform(data[['avgPrice']])\n",
    "            corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "            correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 전체 데이터 상관계수 계산\n",
    "overall_correlations = calculate_overall_correlation(merged_data)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"전체 지역과 대게 가격의 상관계수:\")\n",
    "for key, value in overall_correlations.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgPrice': np.float64(0.9999999999999998),\n",
       " '지점': np.float64(-0.062196129817206985),\n",
       " '풍속(m/s)': np.float64(0.30054166259938275),\n",
       " '풍향(deg)': np.float64(0.10262992590325193),\n",
       " 'GUST풍속(m/s)': np.float64(0.3285639726206786),\n",
       " '현지기압(hPa)': np.float64(0.521052311015256),\n",
       " '습도(%)': np.float64(nan),\n",
       " '기온(°C)': np.float64(-0.5116191346520339),\n",
       " '수온(°C)': np.float64(-0.3867970906283041),\n",
       " '최대파고(m)': np.float64(0.25894650729983065),\n",
       " '유의파고(m)': np.float64(0.2670293735014785),\n",
       " '평균파고(m)': np.float64(0.2646177465494437),\n",
       " '파주기(sec)': np.float64(0.018008969607395835),\n",
       " '파향(deg)': np.float64(0.20783479976598376)}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대게 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '대게'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "# 각 파일을 개별적으로 처리 후 리스트에 저장\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby(['지점', '날짜']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 지역별 데이터 분리 (부안, 가거도, 통영)\n",
    "selected_locations = {'부안': [22186]}\n",
    "df_gageodo = daily_avg[daily_avg['지점'].isin(selected_locations['부안'])].groupby('날짜').mean().reset_index()\n",
    "\n",
    "# 모든 지역 데이터 통합\n",
    "all_weather_data = pd.concat([df_buan, df_gageodo, df_tongyoung]).groupby('날짜').mean().reset_index()\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_correlations(weather_df, price_df):\n",
    "    merged = pd.merge(price_df, weather_df, on='날짜', how='inner')\n",
    "    numeric_cols = merged.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        scaler = StandardScaler()\n",
    "        weather_scaled = scaler.fit_transform(merged[[col]])\n",
    "        price_scaled = scaler.fit_transform(merged[['avgPrice']])\n",
    "        corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "        correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 개별 항목과의 상관계수 계산\n",
    "individual_correlations = calculate_correlations(all_weather_data, rockfish_prices)\n",
    "individual_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   이하 광어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 지역과 광어 가격의 상관계수:\n",
      "지점: 0.7861\n",
      "풍속(m/s): 0.0574\n",
      "풍향(deg): 0.0240\n",
      "GUST풍속(m/s): 0.0753\n",
      "현지기압(hPa): 0.0801\n",
      "습도(%): 0.0002\n",
      "기온(°C): -0.0179\n",
      "수온(°C): 0.0558\n",
      "최대파고(m): 0.0213\n",
      "유의파고(m): 0.0469\n",
      "평균파고(m): 0.0241\n",
      "파주기(sec): -0.1448\n",
      "파향(deg): -0.0109\n"
     ]
    }
   ],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '광어'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby('날짜').mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 기상 데이터와 가격 데이터 병합\n",
    "merged_data = pd.merge(rockfish_prices, daily_avg, on='날짜', how='inner')\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_overall_correlation(data):\n",
    "    numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col != 'avgPrice':\n",
    "            scaler = StandardScaler()\n",
    "            weather_scaled = scaler.fit_transform(data[[col]])\n",
    "            price_scaled = scaler.fit_transform(data[['avgPrice']])\n",
    "            corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "            correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 전체 데이터 상관계수 계산\n",
    "overall_correlations = calculate_overall_correlation(merged_data)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"전체 지역과 광어 가격의 상관계수:\")\n",
    "for key, value in overall_correlations.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgPrice': np.float64(1.0),\n",
       " '지점': np.float64(0.5372792955026775),\n",
       " '풍속(m/s)': np.float64(0.06442489586061431),\n",
       " '풍향(deg)': np.float64(-0.006991582286604785),\n",
       " 'GUST풍속(m/s)': np.float64(0.10348563396205601),\n",
       " '현지기압(hPa)': np.float64(0.07840365716056726),\n",
       " '습도(%)': np.float64(-0.013587590042486906),\n",
       " '기온(°C)': np.float64(0.005764803272428218),\n",
       " '수온(°C)': np.float64(0.07661706420517839),\n",
       " '최대파고(m)': np.float64(0.07568211235681843),\n",
       " '유의파고(m)': np.float64(0.10095978866152949),\n",
       " '평균파고(m)': np.float64(0.09050118317151007),\n",
       " '파주기(sec)': np.float64(-0.19212964624737272),\n",
       " '파향(deg)': np.float64(0.04337381929813404)}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우럭 가격 데이터 로드\n",
    "price_data = pd.read_csv('../data/processed/item_price_lag_filled.csv')\n",
    "price_data['priceDate'] = pd.to_datetime(price_data['priceDate'])\n",
    "price_data = price_data[price_data['priceDate'] >= '2018-01-01']\n",
    "price_data['날짜'] = price_data['priceDate'].dt.date\n",
    "rockfish_prices = price_data[price_data['item'] == '광어'].groupby('날짜')['avgPrice'].mean().reset_index()\n",
    "\n",
    "# 여러 개의 기상 데이터 파일 불러오기\n",
    "file_list = glob.glob('../data/raw/forecast_1525/forecast_*.csv')\n",
    "\n",
    "# 각 파일을 개별적으로 처리 후 리스트에 저장\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='euc-kr')\n",
    "    df['일시'] = pd.to_datetime(df['일시'])\n",
    "    df['날짜'] = df['일시'].dt.date\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 데이터를 병합\n",
    "forecast_df = pd.concat(df_list, ignore_index=True)\n",
    "daily_avg = forecast_df.groupby(['지점', '날짜']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 지역별 데이터 분리 (부안, 가거도, 통영)\n",
    "selected_locations = {'가거도': [22297, 22193], '마라도': 22188, '통영': 22188}\n",
    "df_gageodo = daily_avg[daily_avg['지점'].isin(selected_locations['가거도'])].groupby('날짜').mean().reset_index()\n",
    "df_tongyoung = daily_avg[daily_avg['지점'] == selected_locations['통영']]\n",
    "df_marado = daily_avg[daily_avg['지점'] == selected_locations['마라도']]\n",
    "\n",
    "# 모든 지역 데이터 통합\n",
    "all_weather_data = pd.concat([df_buan, df_gageodo, df_tongyoung]).groupby('날짜').mean().reset_index()\n",
    "\n",
    "# 유사도 분석 함수\n",
    "def calculate_correlations(weather_df, price_df):\n",
    "    merged = pd.merge(price_df, weather_df, on='날짜', how='inner')\n",
    "    numeric_cols = merged.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlations = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        scaler = StandardScaler()\n",
    "        weather_scaled = scaler.fit_transform(merged[[col]])\n",
    "        price_scaled = scaler.fit_transform(merged[['avgPrice']])\n",
    "        corr, _ = pearsonr(price_scaled.flatten(), weather_scaled.flatten())\n",
    "        correlations[col] = corr\n",
    "\n",
    "    return correlations\n",
    "\n",
    "# 개별 항목과의 상관계수 계산\n",
    "individual_correlations = calculate_correlations(all_weather_data, rockfish_prices)\n",
    "individual_correlations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env311_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
